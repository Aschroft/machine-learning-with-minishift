
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>Lab 1 - Training and Deploying Machine Learning Models with Containers Â· GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="CPU-MEMORY.html" />
    
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">Machine Learning with Minishift (OpenShift)</li>
        
        
    
        <li class="chapter active" data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    Lab 1 - Training and Deploying Machine Learning Models with Containers
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1" data-path="CPU-MEMORY.html">
            
                <a href="CPU-MEMORY.html">
            
                    
                    Lab 1.1 - Increasing CPU and Memory
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >Lab 1 - Training and Deploying Machine Learning Models with Containers</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="training-and-deploying-machine-learning-models-with-containers">Training and Deploying Machine Learning Models with Containers</h1>
<h2 id="machine-learning-dependencies-are-a-hassle">Machine learning dependencies are a hassle...</h2>
<p>Between ensuring that the right version Python/Pip are installed on your system, and that it doesn&apos;t conflict with other Python/Pip versions on your system AND that when you deploy your model to the cloud that the versions of the dependencies you&apos;ve used in your projects are still compatible with the version on your cloud-based system, it&apos;s a wonder that we ever get any time to focus on building and training our neural networks.</p>
<p>Fortunately, there&apos;s a way to ensure that all of this is a never a problem again - Containers! (specifically, <a href="https://github.com/minishift/minishift" target="_blank">Minishift</a> )</p>
<p>With containers, we can create a clean, virtual environment to setup and train our neural networks in, and then deploy them at scale with the <em>exact same</em> same environment. No more dependency hell!</p>
<h2 id="but-wont-that-be-slower">&quot;But... won&apos;t that be slower?&quot;</h2>
<p>As with everything in life, there are caveats to this approach. You are training your network on a virtualised system, so you&apos;re not going to get the full, raw power of your machine being utilised in the training process. Even with small networks, training can take quite some time, even longer inside a virtual environment. However, if you&apos;re a machine learning focussed developer with myriad networks to iterate and train, managing all of those dependencies can take hours to configure, and there&apos;s no guarentee that if there isn&apos;t a problem on your system, that there won&apos;t be when it&apos;s deployed to the production environment.</p>
<p>Although this approach will take longer to train, the time savings in reducing the complexity of your setup should work to offset, <em>and</em> when you complete this workshop, you&apos;ll be able to deploy your model to a super-scalable OpenShift Cluser (if you so wish) where you can scale to meet the needs of your users in next to no time at all.</p>
<h2 id="cant-i-just-use-a-virtual-environment-instead">&quot;Can&apos;t I just use a Virtual Environment instead?&quot;</h2>
<p>Absolutely, if that works for you, go for it, but depending on the virtual environment you&apos;re using, it can be equally as awkward to prepare your project as managing the dependencies manually (in fact, I had the idea for this workshop after spending 6 hours fighting with my local environment). There&apos;s also guarentee that the environment you deploy your application to will have a matching configuration without some pre-emptive tweaking.</p>
<h2 id="ok-im-interested">&quot;OK... I&apos;m interested...&quot;</h2>
<p>Cracking, then let&apos;s get started!</p>
<h2 id="in-this-workshop-you-will-learn">In this workshop you will learn...</h2>
<p>1) How to build a Convolutional Neural Network (CNN) that can detect handwritten digits (with Keras and the MNIST dataset)</p>
<p>2) How to train and deploy a CNN with the Flask web framework and Keras</p>
<p>3) How to install and run Minishift (a locally run OpenShift cluster of one image) on your machine</p>
<p>4) How to create a project in OpenShift</p>
<p>5) How to create an app in OpenShift and pull the source code for application from GitHub</p>
<p>By the end, you&apos;ll end up with a natty web app that will tell you what characters you&apos;re drawing, that&apos;ll look like this:</p>
<p><img src="resources/tada.gif" alt="A video demonstrating the classification web app"></p>
<h2 id="before-we-start">Before We Start...</h2>
<p>It&apos;s probably best that you install Minishift before we start diving into neural networking goodness. <a href="https://twitter.com/Moffusa" target="_blank">Mofe Salami</a> has put together a <a href="https://github.com/IBMDeveloperUK/minishift101/tree/master/workshop" target="_blank">fantastic workshop</a> that walks you through the installation and basic setup of Minishift. If you pop on over there and follow just the setup steps of the workshop, and then head back here, we&apos;ll be good to crack on.</p>
<h2 id="you-will-need">You Will Need:</h2>
<ol>
<li>A GitHub account</li>
<li>A macOS/Windows/Linux system capable of running Minishift</li>
<li>A modern web browser</li>
</ol>
<h2 id="recognising-handwritten-digits-with-keras--the-mnist-dataset">Recognising Handwritten Digits with Keras + the MNIST Dataset</h2>
<p>Training neural networks (NNs) to classify handwritten digits has become something of a &quot;Hello, World&quot; for developers looking to start tinkering with neural networks. The reasons for this are myriad, but three stand out:</p>
<ol>
<li>The dataset is small, so the network can be trained in a short space of time.</li>
<li>For a very long time, computers struggled to recognise natural human input, but with NNs the problem is essentially trivial to solve (we&apos;ll likely get a &gt; 98% accuracy with the model we&apos;ll build)</li>
<li>The architecture for recognizing handwritten digits is reuseable for wider image classification cases, so if you&apos;re looking to analyse visual datasets with CNNs, MNIST is a great way to cut your teeth.</li>
</ol>
<h2 id="starting-your-project">Starting Your Project</h2>
<p>The code in this repo is a scaffold for the neural network and app that you&apos;ll end up with if you follow this workshop to the end.</p>
<p>So we can get the full benefit of Minishift&apos;s ability to pull code from a centralised repository and deploy it, you&apos;ll need to fork this repo to create your own version of it to work from.</p>
<p>You can do that with the following steps</p>
<ol>
<li>If you&apos;ve not done so already, log in to your GitHub account (or create one <a href="https://github.com/join" target="_blank">here</a> .</li>
<li>Head back to this <a href="https://github.com/IraAngeles-IBM/machine-learning-with-minishift" target="_blank">repository</a> and then click the fork button at the very top of the UI. It looks like this:</li>
</ol>
<p><code>https://github.com/IraAngeles-IBM/machine-learning-with-minishift</code></p>
<p><img src="resources/fork_btn.png" alt="An image highlighting to fork button"></p>
<p>This will create a copy of this repository that you&apos;ll be able to make changes to, and deploy from.</p>
<ol>
<li>Once the forking process has completed, you need to clone it to your local system. You can do this by clicking the green &quot;Clone or download&quot; button just beneath the navigation for your repo, and then copying either the HTTPS or SSH link in the dialog that appears.</li>
</ol>
<p><img src="resources/clone.png" alt="An image highlighting to fork button">
<img src="resources/clone_link.png" alt="An image highlighting to fork button"></p>
<ol>
<li><p>Once you&apos;ve copied either link, head to your terminal and enter: <code>git clone &lt;URL YOU JUST COPIED&gt;</code></p>
</li>
<li><p>This will copy your forked version of the project to your local system. Now we&apos;re ready to start building a neural network! &#x1F389;</p>
</li>
</ol>
<h2 id="a-quick-tour">A Quick Tour</h2>
<p>If you take a moment to look at the project you just cloned, you&apos;ll see a bunch of files and folders. Here is a brief description of each one</p>
<ol>
<li><code>reference</code> - A complete implementation of the project that we&apos;ll be making.</li>
<li><code>app.py</code> - The main entry point for our program. When we run our project shortly, Minishift will look for and execute this script</li>
<li><code>requirements.txt</code> - A text file which describes which dependencies our project will need to install to support our program.</li>
<li><code>server.py</code> - The code that will serve our prediction web app.</li>
<li><code>train.py</code> - The code that contains our neural network which will begin training the first time we run our app.</li>
</ol>
<h2 id="building-our-neural-network">Building Our Neural Network</h2>
<h3 id="importing-dependencies">Importing Dependencies</h3>
<p>Before we can worry about training and/or deploying our neural network, we first need to construct it! We&apos;ll be using the demo code from the Keras documentation to get us started quickly. You can <a href="https://keras.io/examples/mnist_cnn/" target="_blank">head over there</a> to read about that (or other examples), or you can stick around here where we&apos;ll walk through a few of the blocks of code and explain their function as we work through them.</p>
<p>With your favourite IDE, open the file <code>train.py</code>. This is where the code that creates, trains, and stores our model for later deployment will live.</p>
<p>First, we need to import the dependencies that our project will need to run. You don&apos;t need to have these installed on your system, Minishift will take care of this later.</p>
<p>In <code>train.py</code> the following code block at the top of the file:</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> keras
<span class="hljs-keyword">from</span> keras.datasets <span class="hljs-keyword">import</span> mnist
<span class="hljs-keyword">from</span> keras.models <span class="hljs-keyword">import</span> Sequential
<span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Dense, Dropout, Flatten
<span class="hljs-keyword">from</span> keras.layers <span class="hljs-keyword">import</span> Conv2D, MaxPooling2D
<span class="hljs-keyword">from</span> keras <span class="hljs-keyword">import</span> backend <span class="hljs-keyword">as</span> K
</code></pre>
<h3 id="preparing-our-data-for-training">Preparing our data for training</h3>
<p>Next, we&apos;ll create a function <code>start</code> which our application will call to start training our model when we spin up our container (if a model hasn&apos;t already been trained).</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start</span><span class="hljs-params">()</span>:</span>

    batch_size = <span class="hljs-number">128</span>
    num_classes = <span class="hljs-number">10</span>
    epochs = <span class="hljs-number">12</span>

    <span class="hljs-comment"># input image dimensions</span>
    img_rows, img_cols = <span class="hljs-number">28</span>, <span class="hljs-number">28</span>

    <span class="hljs-comment"># the data, split between train and test sets</span>
    (x_train, y_train), (x_test, y_test) = mnist.load_data()
</code></pre>
<p>The variables <code>batch_size</code>, <code>num_classes</code>, and <code>epochs</code> tell our program how to digit images to load into memory and pass through our network (<code>batch_size</code>), how many different types of digits (or classes) there are (<code>num_classes</code>), and how many times to pass the entire set through the neural network during the training phase <code>epochs</code>.</p>
<p><code>img_rows, img_cols = 28, 28</code> will be used by our neural network to determine the <em>shape of our data</em>. Described <a href="https://towardsdatascience.com/understanding-input-and-output-shapes-in-convolution-network-keras-f143923d56ca" target="_blank">here</a> as: </p>
<p><strong><em>&quot;[...] input data has a shape of (batch_size, height, width, depth), where the first dimension represents the batch size of the image and other three dimensions represent dimensions of the image which are height, width and depth. For some of you who are wondering what is the depth of the image, it&#x2019;s nothing but the number of colour channel. For example, RGB image would have a depth of 3 and the greyscale image would have a depth of 1.&quot;</em></strong></p>
<p><code>(x_train, y_train), (x_test, y_test)</code> are variables that will have the data from the MNISt dataset split up into training and validation sets that will be used by the neural network to confirm whether or not it&apos;s getting better at the job we&apos;ve assigned it.</p>
<pre><code class="lang-python">    <span class="hljs-keyword">if</span> K.image_data_format() == <span class="hljs-string">&apos;channels_first&apos;</span>:
        x_train = x_train.reshape(x_train.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>, img_rows, img_cols)
        x_test = x_test.reshape(x_test.shape[<span class="hljs-number">0</span>], <span class="hljs-number">1</span>, img_rows, img_cols)
        input_shape = (<span class="hljs-number">1</span>, img_rows, img_cols)
    <span class="hljs-keyword">else</span>:
        x_train = x_train.reshape(x_train.shape[<span class="hljs-number">0</span>], img_rows, img_cols, <span class="hljs-number">1</span>)
        x_test = x_test.reshape(x_test.shape[<span class="hljs-number">0</span>], img_rows, img_cols, <span class="hljs-number">1</span>)
        input_shape = (img_rows, img_cols, <span class="hljs-number">1</span>)
</code></pre>
<p>Depending on the data being processed, some image datasets will have their data stored in a 3-Dimensional array in the following order <code>[channels][rows][cols]</code> - This is called <em>&quot;channel-first&quot;</em> data. Conversely, other image datasets will have their information stored <code>[rows][cols][channels]</code> - <em>&quot;channel-last&quot;</em>. This little snippet of code is just a little bit of sugar that sets up our neural network to receive the information regardless of which way around it is.</p>
<p>The next snippet of code is the final bit of processing of our dataset neccessary to pass it through the network we&apos;re about to construct. Copy the following code block and paste it on a new line just after the last code snippet.</p>
<pre><code class="lang-python">    x_train = x_train.astype(<span class="hljs-string">&apos;float32&apos;</span>)
    x_test = x_test.astype(<span class="hljs-string">&apos;float32&apos;</span>)
    x_train /= <span class="hljs-number">255</span>
    x_test /= <span class="hljs-number">255</span>
    print(<span class="hljs-string">&apos;x_train shape:&apos;</span>, x_train.shape)
    print(x_train.shape[<span class="hljs-number">0</span>], <span class="hljs-string">&apos;train samples&apos;</span>)
    print(x_test.shape[<span class="hljs-number">0</span>], <span class="hljs-string">&apos;test samples&apos;</span>)

    <span class="hljs-comment"># convert class vectors to binary class matrices</span>
    y_train = keras.utils.to_categorical(y_train, num_classes)
    y_test = keras.utils.to_categorical(y_test, num_classes)
</code></pre>
<p>Here, we&apos;re first casting all of the values describing each image to floats. Next, we divide those values by 255 (the maximum value for a channel - R, G, or B - in a pixel for an RGB image) so that it&apos;s a value between 0 and 1. We then <code>print</code> out the data for the first image from our training and test datasets</p>
<p><code>y_train</code> and <code>y_test</code> contain the labels of each of the images in our datasets (otherwise our neural network wouldn&apos;t know what any of the data in <code>x_train</code> or <code>x_test</code> actually meant). With <code>keras.utils.to_categorical(y_train, num_classes)</code> we&apos;re converting the labels to an index in a matrix which maps to the original categorisations of the images.</p>
<h3 id="constructing-our-model">Constructing our model</h3>
<p>For our project, we&apos;re going to create a basic 2-Dimensional Convolutional Neural Network. This architecture has been shown to be very effective at recognising patterns in images, and because it&apos;s a sequential model (a model data passes from each layer to the next) it&apos;s considered to be more more legible than other similarly tasked networks.</p>
<pre><code class="lang-python">    model = Sequential()
    model.add(Conv2D(<span class="hljs-number">32</span>, kernel_size=(<span class="hljs-number">3</span>, <span class="hljs-number">3</span>),
                    activation=<span class="hljs-string">&apos;relu&apos;</span>,
                    input_shape=input_shape))
    model.add(Conv2D(<span class="hljs-number">64</span>, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), activation=<span class="hljs-string">&apos;relu&apos;</span>))
    model.add(MaxPooling2D(pool_size=(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>)))
    model.add(Dropout(<span class="hljs-number">0.25</span>))
    model.add(Flatten())
    model.add(Dense(<span class="hljs-number">128</span>, activation=<span class="hljs-string">&apos;relu&apos;</span>))
    model.add(Dropout(<span class="hljs-number">0.5</span>))
    model.add(Dense(num_classes, activation=<span class="hljs-string">&apos;softmax&apos;</span>))
</code></pre>
<p>Our first variable <code>model</code> is where we&apos;ll create a reference that we can use to construct each layer of neurons in our neural network.</p>
<p>Next, we add a 2D Convolutional layer to our network with <code>model.add(Conv2D(32 kernel_size=(3, 3), activation=&apos;relu&apos;, input_shape=input_shape))</code>. This layer &quot;convolves&quot; around our image in an attempt to find patterns and structures that it can use in classifying our images. Adit Deshpande has written a <a href="https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/" target="_blank">great blog post</a> where you can read more about what&apos;s going on in this layer, if you&apos;re so inclined.</p>
<p>We compound this effect with a second convolutional layer <code>model.add(Conv2D(64, (3, 3), activation=&apos;relu&apos;))</code>.</p>
<p>After that, with <code>model.add(MaxPooling2D(pool_size=(2, 2)))</code>, we create a pooling layer, which is akin to downsampling the results of the two previous layers so that only the most prevalent features pass through to the next layer.</p>
<p>Our next layer is a &quot;dropout&quot; layer. This layer of neurons will randomly ignore input as the network is trained. This encourages the network to be more robust, by depending on a variety of connections between the next and previous layers, rather than relying on a we, heavily weighted connections which could possibly have too much of a say in the ultimate classifcation of the image. </p>
<p>Next, we flatten the input the input from our dropout layer with <code>model.add(Flatten())</code> into a 1-Dimensional array. Up until this point, our data has maintained the original shape, albeit modified, from when we passed it through to our network.</p>
<p>The next layer, <code>model.add(Dense(128, activation=&apos;relu&apos;))</code> a densely connected layer of neurons with a ReLu activation function serves to act as filter for neurons that have haven&apos;t received enough input to be activated. ReLu is a permissive activation function, so strong, and medium strength activations will be allowed to pass through and activate neurons in the next layer of our network, whereas weak activations will not. </p>
<p>Finally, we have two more layers of neurons. Another dropout layer, and another Densely connected layer. The final layer has the same number of outputs as the number of classes that we wish to categorise our images as. Each neuron corresponds to a label for each class, whichever neuron has the highest activation value will be the classification assigned to the image passed through to the network for training / prediction.</p>
<h3 id="compiling-our-model-and-training">Compiling our model and training</h3>
<p>Now that we&apos;ve constructed our model, it&apos;s time to compile it. This is the stage where we tell our neural networks how to measure it&apos;s success in categorising a given input, and start passing through data for training</p>
<p>The following is the code that will compile our model on a new line after out last code snippet.</p>
<pre><code class="lang-python">    model.compile(loss=keras.losses.categorical_crossentropy,
                optimizer=keras.optimizers.Adadelta(),
                metrics=[<span class="hljs-string">&apos;accuracy&apos;</span>])
</code></pre>
<p>And next, we&apos;ll start passing through our data with <code>model.fit()</code></p>
<pre><code class="lang-python">    model.fit(x_train, y_train,
            batch_size=batch_size,
            epochs=epochs,
            verbose=<span class="hljs-number">1</span>,
            validation_data=(x_test, y_test))
    score = model.evaluate(x_test, y_test, verbose=<span class="hljs-number">0</span>)
    print(<span class="hljs-string">&apos;Test loss:&apos;</span>, score[<span class="hljs-number">0</span>])
    print(<span class="hljs-string">&apos;Test accuracy:&apos;</span>, score[<span class="hljs-number">1</span>])
</code></pre>
<h3 id="saving-our-model">Saving our model</h3>
<p>Once our network has been trained, it&apos;s time to save our model so we can use it later. Fortunately, this is a comparatively simple affair.</p>
<p>The following line of code on a new line beneath our last snippet.</p>
<pre><code class="lang-python">    model.save(<span class="hljs-string">&apos;mnist.h5&apos;</span>)
</code></pre>
<p>When our neural network has finished training, it&apos;s knowledge will be saved to a file &quot;mnist.h5&quot; in the same directory as our project.</p>
<h2 id="serving-our-neural-network">Serving Our Neural Network</h2>
<p>Once we&apos;ve trained our neural network, we&apos;ll want to put it somewhere for people to use it, so we&apos;ll create a simple HTTP server with the Flask framework.</p>
<p>For this, we&apos;ll be working in the <code>server.py</code> file. Open it up for editing in your favourite IDE.</p>
<h3 id="importing-dependencies">Importing Dependencies</h3>
<p>As with our <code>train.py</code> we need to import the dependencies that our server will need to function - namely, Flask, Keras, and NumPy. The following code at the top of the <code>server.py</code> file.</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> Flask, request
<span class="hljs-keyword">from</span> flask <span class="hljs-keyword">import</span> render_template
<span class="hljs-keyword">import</span> keras, sys, json
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
application = Flask(__name__)

stored_model = <span class="hljs-keyword">None</span>
</code></pre>
<p>We&apos;ve also created two variables <code>application</code> and <code>stored_model</code>. <code>application</code> creates an instance of the Flask HTTP server that we can configure to listen for connections. The <code>stored_model</code> variable is where we&apos;ll load our trained model that we create when <code>train.py</code> is run. </p>
<p>Next, we need to define the paths that the server will serve resources on. The following block of code on a new line after <code>stored_model</code>:</p>
<pre><code class="lang-python"><span class="hljs-meta">@application.route(&quot;/&quot;)</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hello</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-keyword">return</span> render_template(<span class="hljs-string">&apos;index.html&apos;</span>)

<span class="hljs-meta">@application.route(&quot;/predict&quot;, methods=[&apos;POST&apos;])</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">classifyCharacter</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-keyword">global</span> stored_model

    body = request.get_json()

    reshapedData = np.array(body[<span class="hljs-string">&apos;data&apos;</span>])
    reshapedData = reshapedData.reshape(<span class="hljs-number">1</span>,<span class="hljs-number">28</span>,<span class="hljs-number">28</span>,<span class="hljs-number">1</span>)

    <span class="hljs-keyword">return</span> json.dumps( { <span class="hljs-string">&apos;prediction&apos;</span> : int(stored_model.predict_classes( reshapedData )[<span class="hljs-number">0</span>]) } )
</code></pre>
<p>Our first route will serve the <code>index.html</code> file from the <code>resources</code> folder (included when from the repo that we forked our copy from) when a request is made to <code>/</code> on our server.</p>
<p>The second route will accept an array of pixel values passed in a JSON formatted array to <code>/predict</code>. These values will be reshaped to fit the dimensions that our neural network expects as input, and will then be classified by the network. The result of the neural network is then passed back as a response to the request in JSON formatted object. </p>
<p>Finally, we&apos;ll create a function which we will be able to trigger to start the server listening on a given port. The following below the last block of code.</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">start</span><span class="hljs-params">()</span>:</span>
    <span class="hljs-keyword">global</span> stored_model

    stored_model = keras.models.load_model(<span class="hljs-string">&apos;mnist.h5&apos;</span>)
    stored_model._make_predict_function()

    application.run(host=<span class="hljs-string">&apos;0.0.0.0&apos;</span>, port=<span class="hljs-number">8080</span>)
</code></pre>
<p>Before we start listening for requests from client, we need to load our trained model for classifying our inputs with <code>keras.models.load_model(&apos;mnist.h5&apos;)</code>. </p>
<p>Once that&apos;s loaded, we&apos;ll tell our Flask server to start listening for requests. By default, Minishift will pass through traffic to an application on port <code>8080</code>. As such, we will tell our server to listen for requests on that port.</p>
<h2 id="to-train-or-to-serve">To train, or to serve?</h2>
<p>So, now we have code to train and code to serve it to people once it&apos;s ready, but how will Minishift know what to do when? </p>
<p>Simple! We&apos;ll write a little bit of code that will check if there&apos;s a model ready to be used, if there is, we&apos;ll start our server. If there isn&apos;t, then we&apos;ll train our model, and start the server when it&apos;s finished.</p>
<p>When Minishift creates a pod with a Python application, it looks for an <code>app.py</code> file to run. In this file, we&apos;ll import our <code>train.py</code> and <code>serve.py</code> files as dependencies, check whether a model exists, and then act accordingly. </p>
<p>The following code block is in <code>app.py</code> file...</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf
<span class="hljs-keyword">import</span> os.path

<span class="hljs-keyword">import</span> server

<span class="hljs-comment"># Check if pre-trained model already exists</span>
<span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(<span class="hljs-string">&apos;mnist.h5&apos;</span>):
    <span class="hljs-keyword">import</span> train

    train.start()

    print(<span class="hljs-string">&apos;Training complete. Starting server&apos;</span>)
    server.start()

<span class="hljs-keyword">else</span>:
    print(<span class="hljs-string">&apos;Model exists. Starting server&apos;</span>)
    server.start()
</code></pre>
<p>Now it&apos;s time for some Minishift goodness.</p>
<h2 id="deploying-our-application-to-minishift">Deploying our application to Minishift.</h2>
<h3 id="creating-our-project--application">Creating our project + application</h3>
<p>If you didn&apos;t install and setup Minishift at the start of this tutorial with <a href="https://github.com/IBMDeveloperUK/minishift101/tree/master/workshop" target="_blank">Mofe&apos;s guide</a>, go and do that now.</p>
<p>If you have, then it&apos;s time to fire Minishift up &#x1F680;</p>
<p>In your terminal window execute the following to start Minishift:</p>
<p><code>minishift start --vm-driver hyperkit --network-nameserver 8.8.8.8</code></p>
<p>This will spin up the Minishift platform with the hyperkit driver, and allow local network traffic to access it.</p>
<p>Depending on your system&apos;s resource, it may take a little while to spin up, so take the opportunity to go and grab a cup of tea.</p>
<p>Once minishift has finished spinning up, you should see an output in your terminal a bit like the following:</p>
<p><img src="resources/minishift_start.png" alt="A image showing the text output of Minishift once it&apos;s started"></p>
<p>Your https:// address will be different to the one displayed here.</p>
<p>Copy that URL and enter it into your browser. You should be presented with a login dialog that looks like this:</p>
<p><img src="resources/minishift_login.png" alt="A image showing the Minishift login page"></p>
<p>For the username enter <code>developer</code>, for the password, enter anything you like at all.</p>
<p>Once you&apos;ve logged in, you&apos;ll be presented with the Minishift console. </p>
<p><img src="resources/minishift_console.png" alt="A image showing the Minishift console"></p>
<p>Here, we can create a project and configure an app to be run. So let&apos;s do that!</p>
<p>In the console page, there&apos;s a big, friendly &quot;Python&quot; button. Click it to start creating our project.</p>
<p><img src="resources/minishift_project_creation.png" alt="A image showing the Minishift project creation UI"></p>
<p>Fill in the values for project with the following values:</p>
<h4 id="project-name">Project Name</h4>
<p>keras-mnist</p>
<h4 id="project-display-name">Project Display Name</h4>
<p>keras-mnist</p>
<h4 id="application-name">Application Name</h4>
<p>mnist-recognition</p>
<p>For the Git repository, we want to add the URL for the forked copy of the project Git repo that we just commited to. Head to your forked version and click the &apos;Clone or download&apos; button again. Make sure to copy the HTTP version of the URL, as Minishift hasn&apos;t been configured to get source code over SSH. Paste that value into the Git Repository field and then click &apos;Next&apos;.</p>
<p>You&apos;ll then see a dialog describing the creation of your project and app. Click &apos;Close&apos; when this process has finished.</p>
<h3 id="building-our-application">Building our application</h3>
<p>At this point, Minishift will request the source code for our project and copy it to start the build process. On the right hand side of the console, you will see your newly created project. Click on it to head to the admin page for it.</p>
<p>On the left-hand side of your console, you will see a list of options. Once our source code has been retrieved from GitHub, Minishift will start to build our app. We can check out how that&apos;s going by clicking on <code>Build</code> (highlighted in red), then <code>Builds</code> (highlighted in green) from the menu, and then clicking on the number for our build along side our app (highlighted in blue).</p>
<p><img src="resources/minishift_build.png" alt="A image showing the Minishift admin dashboard"></p>
<p>This will take us through to the build status page for our app. By clicking on <code>Logs</code> (highlighted in orange), we can track the progress of our apps build.</p>
<p><img src="resources/minishift_app_status_page.png" alt="A image showing the Minishift app build dashboard"></p>
<p>Which looks like this:</p>
<p><img src="resources/minishift_build_logs.png" alt="A image showing the Minishift app build dashboard"></p>
<h3 id="training-our-network">Training our network</h3>
<p>Once the build has finished, it will start our app!</p>
<p>On first run, our app won&apos;t have a trained network for it to make classifications with, so it&apos;ll grab the MNIST dataset and start training the neural network we created in <code>train.py</code>.</p>
<p>Depending on the system, this can take a while (what doesn&apos;t in machine learning?) but we can check on the status of the training from our console.</p>
<p>To view the state of our app, we can click on <code>Applications</code> on the left hand side of the screen (highlighted in fuscia), and then <code>Deployments</code> (highlighted in green).</p>
<p><img src="resources/minishift_deploys.png" alt="A image showing the Minishift app build dashboard"></p>
<p>This takes us through to our deployments page. Click on the highlighted number under &apos;Last Version&apos; for your app, and that will take you to the overview for your application.</p>
<p>From here, we can click on the <code>Logs</code> tab (highlighted in red) to view the training progress of our neural network.</p>
<p><img src="resources/minishift_app_status_page.png" alt="A image showing the Minishift app build overview"></p>
<p><img src="resources/minishift_training_progress.png" alt="A image showing the Minishift training logs"></p>
<p>This will take some time to complete, so finish up your last tea, and go and grab another &#x2615;&#xFE0F;</p>
<h3 id="build-complete-time-to-play">Build complete! Time to play!</h3>
<p>After our model has finished training, our server will spin up and serve a web app that we can use to play with our newly created model.</p>
<p>When the network has been trained, you&apos;ll see some output in your logs like the following:</p>
<p><img src="resources/minishift_build_complete.png" alt="A image showing the Minishift training logs"></p>
<p>The last line tells us that the server has successfully bound to the port we specified (8080) and that it&apos;s ready for traffic.</p>
<p>Our application is running in a pod, so we can&apos;t directly access the URL provided, but Minishift is a natty little piece of software, so it very helpfully gives us a URL that we can use to access the server in our browser.</p>
<p>To find the URL that we can access our app on, click on the <code>Applications</code> tab on the left-hand side of the screen (highlighted in yellow), and then click on <code>Routes</code> (highlighted in blue).</p>
<p><img src="resources/minishift_routes.png" alt="A image showing the Minishift routes tab"></p>
<p>This will take you to the &apos;Routes&apos; page. Once there, click on your application name, and you&apos;ll be taken through to the routes admin page for your app.</p>
<p>On this page, you&apos;ll see a URL (highlighted in red, but yours will be slightly different) that you can use to access the prediction web app that you may remember from the start of the document, and it&apos;s ready to go!</p>
<p><img src="resources/minishift_public_url.png" alt="A image showing the public URL for our application pod"></p>
<p>Click it, and you&apos;ll be taken to our application where you can click and draw a number which our neural network will classify!</p>
<p><img src="resources/tada.gif" alt="A video demonstrating the classification web app"></p>
<p>Go and have some fun, but then do come back here - We&apos;re not quite done yet.</p>
<h3 id="saving-our-model-for-the-big-time">Saving our model for the big time.</h3>
<p>So, we&apos;ve trained our model, spun up our server, and classified some digits. It&apos;s been a ride, but we still need to do a few more small things to ready our app for the big time.</p>
<p>Minishift deployments are ephemeral in nature. If we spin down our deployment, and then spin it back up again, it&apos;ll rebuild our application from scratch, so we&apos;ll lose our model! Now, we don&apos;t want to waste valueable cycles on a public infratructure retraining a model we&apos;ve just trained locally, nor do we want to have our clusters waiting for an age while that completes. Fortunatelym it&apos;s possible to save our newly trained model and have it deploy with our application when we push it to a cloud environment.</p>
<p>To do this, we&apos;re going to SSH into our pod and copy the file to our local system, where we&apos;ll commit it to our Git repo. This way, when we deploy on an <em>Openshift</em> cluster, the pre-trained model will be pulled from our repository and used straight away by our server - no further training required.</p>
<p>Head back to your terminal and follow these steps...</p>
<p>First, we need to make sure we can access the Openshift CLI tool. It <em>should</em> have been setup when we installed Minishift, but it doesn&apos;t always behave, so we can load it into our environment by running the followind command:</p>
<p><code>eval $(minishift oc-env)</code></p>
<p>Next, we want to login with the oc CLI tool with our developer credentials (the same user we&apos;ve been using in the GUI console - don&apos;t worry, you won&apos;t need to remember your password for this)</p>
<p><code>oc login -u developer</code></p>
<p>This will set our user for our following commands.</p>
<p>Next, we want to get a list of pods in our deployment, which we can get with:</p>
<p><code>oc get pods</code></p>
<p>This should output something like this. </p>
<p><img src="resources/minishift_get_pods.png" alt="A list of our pods"></p>
<p>If you, like me, have run multiple builds in Minishift, you may have multiple entries, but we&apos;re not interested in those, we&apos;re only interested in the running pod.</p>
<p>Copy the pod name, and then run the following command to SSH into your machine</p>
<p><code>oc rsh &lt;YOUR POD NAME&gt;</code></p>
<p>This will give you a shell environemt that you can use to interact with your pod. At this point we want to run the following command to list the directory and find our apps current working path</p>
<p><code>ls -la &amp;&amp; pwd</code></p>
<p>This will list all of the files and directories for our application, and then the working directory for our app, which should be something like <code>/opt/app-root/src</code>. Look familiar?</p>
<p><img src="resources/minishift_directories.png" alt="A list of our apps resources"></p>
<p>Notice how there&apos;s a file called <code>mnist.h5</code>. This is the file where our ML model is saved - that&apos;s what we want to save.</p>
<p>Copy the path at the bottom of the output (that&apos;s the path to our apps working directory) and then type <code>exit</code>. This will close our SSH connection.</p>
<p>With the path we&apos;ve just copied, we&apos;re going to download the file to our local filesystem.</p>
<p>Enter the following to download the <code>mnist.h5</code> file from our pod to our local filesystem</p>
<p><code>oc rsync &lt;YOUR POD NAME&gt;:/opt/app-root/src/mnist.h5 ./</code></p>
<p>This will write the <code>mnist.h5</code> file to your local filesystem. Hurrah!</p>
<p>Now, we can commit that to our Git repository so that if we build our application again (either locally, or somewhere in the Cloud) it will use this pre-trained model instead of starting from scratch.</p>
<p>To do this, enter:</p>
<p><code>git add .</code></p>
<p><code>git commit -m &quot;Saving pre-trained model for deployment&quot;</code></p>
<p><code>git push origin master</code></p>
<p>And Voila! We&apos;ve learned how to build, train, and deploy a neural network with Minishift.</p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                
                <a href="CPU-MEMORY.html" class="navigation navigation-next navigation-unique" aria-label="Next page: Lab 1.1 - Increasing CPU and Memory">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"Lab 1 - Training and Deploying Machine Learning Models with Containers","level":"1.1","depth":1,"next":{"title":"Lab 1.1 - Increasing CPU and Memory","level":"1.1.1","depth":2,"path":"CPU-MEMORY.md","ref":"CPU-MEMORY.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":[],"pluginsConfig":{"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"README.md","mtime":"2020-03-10T04:22:31.701Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-03-10T04:23:41.477Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

